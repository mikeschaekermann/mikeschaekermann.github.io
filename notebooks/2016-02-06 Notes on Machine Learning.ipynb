{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notes are a result of my preparation for a midterm exam in [Pascal Poupart](https://cs.uwaterloo.ca/~ppoupart)'s [course on Machine Learning](https://cs.uwaterloo.ca/~ppoupart/teaching/cs485-winter16/) at University of Waterloo in the winter 2016 term. This post is currently a **work in progress (as of February 6, 2016)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Definition by Tom Mitchell (1988): \"A computer program is said to learn from **experience E** with respect to some class of **tasks T** and **performance measure P** if its performance for tasks in T, as measured by P, improves with experience E.\"\n",
    "\n",
    "Inductive Learning: given a training set of examples of the form $(x, f(X))$, return a function $h$ (**hypothesis**) that approximates $f$ (**true underlying function**).\n",
    "\n",
    "The quality measure for hypotheses is **generalization**. A good hypothesis will generalize well, i.e., predict unseen examples correctly. **Ockham's razor** demands to prefer the simplest hypothesis consistent with the input data.\n",
    "\n",
    "Two different types of inductive learning:\n",
    "\n",
    "* **Classification**: range/output space of $f$ is categorical (or discrete)\n",
    "* **Regression**: range/output space of $f$ is continuous\n",
    "\n",
    "**Hypothesis space $H$**: set of all possible $h$\n",
    "\n",
    "**Consistency**: $h$ is consistent if it agrees with $f$ on all examples; it is not always possible to find a consistent $h$ (e.g., due to an insufficient $H$ or noisy input data)\n",
    "\n",
    "**Realizability**: a learning problem is realizable if and only if $f$ is in $H$\n",
    "\n",
    "In general, we will observe a tradeoff between **expressiveness** (i.e., the size of $H$) and the **complexity** of finding a good $h$.\n",
    "\n",
    "**Overfitting**: given a hypothesis space $H$, a hypothesis $h \\in H$ is said to overfit the training data if there exists some alternative hypothesis $h' \\in H$ such that $h$ has smaller error than $h'$ over the training examples, but $h'$ has smaller error than $h$ over the entire distribution of instances.\n",
    "\n",
    "**$k$-fold cross-validation:** you run $k$ experiments, each time putting aside $\\frac{1}{k}$ of the data to test on and, finally, compute the average accuracy of the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "Decision trees (a.k.a. **C**lassification **a**nd **R**egression **T**rees [CART]) represent disjunctions (OR) of conjunctions (AND) of constraints of attribute values.\n",
    "\n",
    "Decision trees have the following **structure**:\n",
    "\n",
    "* **nodes**: attributes\n",
    "* **edges**: attribute values\n",
    "* **leaves**: classes / regression values\n",
    "\n",
    "**Quality measure** for decision trees:\n",
    "\n",
    "* small size\n",
    "* high consistency\n",
    "\n",
    "**Greedy induction** of a decision tree:\n",
    "\n",
    "* depth-first search like construction\n",
    "* a good attribute splits the examples into subsets that are ideally all from the same class or, in other words, that minimizes the residual error\n",
    "\n",
    "**Residual error for classification**:\n",
    "\n",
    "||Error Frequency|Gini Index|Entropy|\n",
    "|---|---|---|---|\n",
    "|**Definition**|$Q_\\tau=\\#\\tau-max_k\\#k$|$Q_\\tau=\\sum_kp_\\tau(k)(1-p_\\tau(k))$|$Q_t=-\\sum_kp_\\tau(k) \\ ld \\ p_\\tau(k)$|\n",
    "|**Explanation**|Number of examples in leaf $\\tau$ minus maximum number of examples in leaf $\\tau$ that belong to any class $k$|Expected misclassification when choosing the class according to $p_\\tau(k)$|Expected # of bits to encode the class of an instance chosen at random according to $p_\\tau(k)$|\n",
    "\n",
    "**Variables:**\n",
    "\n",
    "* $\\tau$: index for leaf $\\tau$\n",
    "* $k$: index for class $k$\n",
    "* $\\#\\tau$: number of examples in leaf $\\tau$\n",
    "* $\\#k$: number of examples in leaf $\\tau$ belonging to class $k$\n",
    "* $p_\\tau(k) = \\frac{\\#k}{\\#\\tau}$\n",
    "\n",
    "**Residual error for regression**:\n",
    "\n",
    "* Let $t_n = f(x_n)$ be the target for the $n^th$ example.\n",
    "* Let $y_t$ be the value returned by leaf $\\tau$.\n",
    "* Let $R_\\tau$ be the set of examples in leaf $\\tau$.\n",
    "* Euclidean error for leaf $\\tau$: $Q_\\tau=\\sum_{n \\in R_\\tau}(t_n-y_n)^2$\n",
    "\n",
    "**Choosing the best attribute** for the next decision layer in the tree:\n",
    "\n",
    "* In leaf $\\tau$, choose attribute $A$ that reduces the residual error the most when expanded:\n",
    "* $A^*=argmax_AQ_\\tau-\\sum_{a \\in A}p_\\tau(A=a)Q_{\\tau a}$, where\n",
    "  * $p_\\tau(A=a)=\\frac{\\#(A=a)}{\\#\\tau}$ denotes the proportion of examples with value $a$ (in attribute $A$) inside node $\\tau$\n",
    "  * $\\tau a$ indexes the node reached by following the edge for attribute value $a$, starting from node $\\tau$\n",
    "  \n",
    "**Techniques to avoid overfitting:**\n",
    "\n",
    "* Stop learning when the curve for testing accuracy, plotted against the tree size, goes down again; this is in practice sometimes hard to achieve because the curve might exhibit high fluctuation\n",
    "* Pruning of statistically irrelevant nodes in a bottom-up fashion\n",
    "  * Remove nodes that improve testing accuracy by less than some threshold\n",
    "  * Regularization: add a penalty term that reflects the tree complexity (e.g., $\\|T\\|=$ #leaves in the tree) and remove leaves with a negative \"regularized\" error reduction: $Q_\\tau-\\sum_{a \\in A}p_\\tau(A=a)Q_{\\tau a}-\\lambda\\|T\\|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture of Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
