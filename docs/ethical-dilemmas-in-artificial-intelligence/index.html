<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Ethical Dilemmas in Artificial Intelligence &#8211; Mike Schaekermann</title>
<meta name="description" content="Today, I would like to draw your attention to a blog post highlighting how self-driving cars will force humans to start thinking about their very basic ethical foundations again [1]. We probably all have read or heard about a plethora of articles pointing out how much more reliable and safe autonomous vehicles have become over the last few months and years. In contrast to that, the article Why Self-Driving Cars Must Be Programmed to Kill [1] reviews a scientific paper [2] posing the question how self-driving cars should be programmed to act in the event of an unavoidable accident.

">
<meta name="keywords" content="artifical intelligence, self-driving cars, ethical dilemmas, experimental ethics, utilitarianism, Mike, Hardy, Schäkermann, Schaekermann, Shaekermann, Shaekerman, Shakerman">


<!-- Twitter Cards -->
<meta name="twitter:title" content="Ethical Dilemmas in Artificial Intelligence">
<meta name="twitter:description" content="Today, I would like to draw your attention to a blog post highlighting how self-driving cars will force humans to start thinking about their very basic ethical foundations again [1]. We probably all have read or heard about a plethora of articles pointing out how much more reliable and safe autonomous vehicles have become over the last few months and years. In contrast to that, the article Why Self-Driving Cars Must Be Programmed to Kill [1] reviews a scientific paper [2] posing the question how self-driving cars should be programmed to act in the event of an unavoidable accident.

">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mikeshake.me/images/default-thumb.png">

<!-- Open Graph -->
<meta property="og:locale" content="en">
<meta property="og:type" content="article">
<meta property="og:title" content="Ethical Dilemmas in Artificial Intelligence">
<meta property="og:description" content="Today, I would like to draw your attention to a blog post highlighting how self-driving cars will force humans to start thinking about their very basic ethical foundations again [1]. We probably all have read or heard about a plethora of articles pointing out how much more reliable and safe autonomous vehicles have become over the last few months and years. In contrast to that, the article Why Self-Driving Cars Must Be Programmed to Kill [1] reviews a scientific paper [2] posing the question how self-driving cars should be programmed to act in the event of an unavoidable accident.

">
<meta property="og:url" content="https://mikeshake.me/ethical-dilemmas-in-artificial-intelligence/">
<meta property="og:site_name" content="Mike Schaekermann">

<meta property="og:image" content="https://mikeshake.me/images/default-thumb.png">






<link rel="canonical" href="https://mikeshake.me/ethical-dilemmas-in-artificial-intelligence/">
<link href="https://mikeshake.me/feed.xml" type="application/atom+xml" rel="alternate" title="Mike Schaekermann Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://mikeshake.me/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="https://mikeshake.me/assets/js/vendor/html5shiv.min.js"></script>
	<script src="https://mikeshake.me/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://mikeshake.me/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- MathJax -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://mikeshake.me/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://mikeshake.me/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://mikeshake.me/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://mikeshake.me/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://mikeshake.me/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://mikeshake.me/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="https://mikeshake.me/">Mike Schaekermann</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="https://mikeshake.me/" >Bio & Research</a></li>
				
				    
				    <li><a href="https://mikeshake.me/projects/" >Projects</a></li>
				
				    
				    <li><a href="https://mikeshake.me/publications/" >Publications</a></li>
				
				    
				    <li><a href="https://mikeshake.me/presentations/" >Presentations</a></li>
				
				    
				    <li><a href="https://mikeshake.me/notes/" >Notes</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">

  <a href="https://mikeshake.me">
  
	  <img src="https://mikeshake.me/images/mike-schaekermann-photo-5.jpg" class="bio-photo" alt="Mike Schaekermann bio photo">
  
  </a>

  <a href="https://mikeshake.me"><h3 itemprop="name">Mike Schaekermann</h3></a>
  <p>Computer Science, Ph.D.<br>Engineering, B.Sc.<br>Medicine, State Exam I</p>
  <a href="mailto:mikeschaekermann@gmail.com" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a>
  
  
  <a href="https://scholar.google.com/citations?user=mwj_ldQAAAAJ" class="author-social" target="_blank"><i class="fa fa-fw fa-google"></i> Google Scholar</a>
  
  <a href="http://linkedin.com/in/mschaeke" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a>
  
  
  
  <a href="http://github.com/mikeschaekermann" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        <h1><a href="https://mikeshake.me/ethical-dilemmas-in-artificial-intelligence/" rel="bookmark" title="Ethical Dilemmas in Artificial Intelligence">Ethical Dilemmas in Artificial Intelligence</a></h1>
      
    </div><!--/ .headline-wrap -->
    <div class="article-wrap">
      <p>Today, I would like to draw your attention to a blog post highlighting how self-driving cars will force humans to start thinking about their very basic ethical foundations again [1]. We probably all have read or heard about a plethora of articles pointing out how much more reliable and safe autonomous vehicles have become over the last few months and years. In contrast to that, the article <em>Why Self-Driving Cars Must Be Programmed to Kill</em> [1] reviews a scientific paper [2] posing the question how self-driving cars should be programmed to act in the event of an unavoidable accident.</p>

<p>Special emphasis in both the article and the cited paper is on the question whether the general ethical premise should be to minimize pain in general and the loss of life in particular. Amongst philosophers, such an approach is called utilitarianism [10]. However, in some situations, such a utilitarian calculation could conclude that the death toll is minimized if the car avoids a group of individuals on the street by swerving into a wall and killing the passenger instead.</p>

<p>The article highlights the importance of such ethical questions with respect to acceptance and adoption of self-driving cars in society. The fact that also media from other domains like business [7] or general news [8] report about this pressing topic indicates the relevance of this discussion for the broader public. It is also emphasized in [2] that carmakers will have to target potentially incompatible objectives: being consistent in algorithmic morality, preventing public rejection of the technology and encouraging customers to buy cars.</p>

<p>In the reviewed paper [2], the authors tackle the problem of ethical dilemmas by employing a new technique, located at the intersection of psychology and philosophy, called experimental ethics. They ran a crowdsourcing experiment asking for people’s opinions about specific scenarios in which the lives of one or more pedestrians could be saved if a car were to avoid the pedestrians by driving into a barrier, killing the passengers of the car or a pedestrian. The overall result of this extensive questionnaire was that most people wished others to drive in utilitarian self-driving cars without being ready to buy and use a utilitarian autonomous vehicle themselves - a comprehensible paradoxon.</p>

<p><img src="https://d267cvn3rvuq91.cloudfront.net/i/images/Ethical%20cars.png?sw=790" />
<em>Image reprinted from paper [2]</em></p>

<p>Another paper [4] takes a bit of a different approach on the same problem stating that the answer to these types of ethical dilemmas cannot be found by employing humans’ ability of ethical reasoning alone because the assignment of blame to either the human programmer or black-box AI processes might be too complex to answer for human beings alone. The authors of this paper argue that we should make use of complementary AI systems to ensure other AI systems do not act illegally or unethically.</p>

<p>In general, I think the presented article highlights the importance of some of the topics we have also discussed in class like reasoning under uncertainty. For example, the authors of [2] describe the scenario of a car avoiding a crash with a motorcycle by driving into a wall taking into account that the chance of survival is higher for the driver of the car than for the rider of the motorcycle. Another example related to the notion of the expected discounted sum of future rewards, alleged in the same paper, highlights the question whether decisions should be adjusted depending on the age of the passengers, given that children, on average, have a longer time ahead of them than adults.</p>

<p>In addition to that, paper [2] also mentions the notion of randomization in decision making to break ties when it comes to irresolvable ethical dilemmas. This idea partially ties in with optimization approaches like simulated annealing or genetic algorithms where randomization is used as a means to explore the solution space in scenarios where it is near to impossible to find the optimal solution in an acceptable time frame.</p>

<p>In my opinion, the discussion of moral dilemmas in the context of self-driving cars is just the tip of the iceberg. The next obvious cases raising similar questions, in my opinion, will be all other types of vehicles that will be equipped with full autonomy in the near future like airplanes, ships and motorcycles. In fact, I think the discussion is fundamentally relevant to all autonomous agents with a large degree of freedom in making decisions, both human and non-human. One example from the medical domain would be a robot performing a Caesarean operation confronted with a scenario in which any decision it could make will lead to the death of either the mother or the child.</p>

<p>In conclusion, I would like to express my opinion that the social implications of this article are mostly positive because all real-life moral dilemmas will force us to explicitly reason about our underlying ethical foundations both as individual human beings and as society as a whole (referring to the approach of experimental ethics proposed in [2]). Essentially, my assumption is that the need for explicitness fosters conscious reflection about our most basic moral values - and how can it get any more explicit than writing algorithmic instructions for a computer? ;)</p>

<h2 id="resources">Resources</h2>

<ul>
  <li>[1] <a href="https://www.technologyreview.com/s/542626/why-self-driving-cars-must-be-programmed-to-kill/">Why Self-Driving Cars Must Be Programmed to Kill</a></li>
  <li>[2] <a href="http://arxiv.org/abs/1510.03346">Autonomous Vehicles Need Experimental Ethics: Are We Ready for Utilitarian Cars?</a></li>
  <li>[3] <a href="http://ed.ted.com/lessons/the-ethical-dilemma-of-self-driving-cars-patrick-lin">The ethical dilemma of self-driving cars</a></li>
  <li>[4] <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2705546">The Ethics Bot: AI Needs Legal and Ethical Guidance</a></li>
  <li>[5] <a href="https://www.technologyreview.com/s/542651/drivers-push-teslas-autopilot-beyond-its-abilities/">Drivers push Tesla’s autopilot beyond its abilities</a></li>
  <li>[6] <a href="https://www.technologyreview.com/s/527756/lazy-humans-shaped-googles-new-autonomous-car/">Lazy humans shaped Google’s new autonomous car</a></li>
  <li>[7] <a href="http://www.businessinsider.com/the-ethical-questions-facing-self-driving-cars-2015-10">The huge, unexpected ethical question that self-driving cars will have to tackle</a></li>
  <li>[8] <a href="http://www.theguardian.com/technology/2015/dec/23/the-problem-with-self-driving-cars-who-controls-the-code">The problem with self-driving cars: who controls the code?</a></li>
  <li>[9] <a href="https://www.technologyreview.com/s/539731/how-to-help-self-driving-cars-make-ethical-decisions/">How to help self-driving cars make ethical decisions</a></li>
  <li>[10] <a href="https://en.wikipedia.org/wiki/Utilitarianism">Utilitarianism</a></li>
</ul>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=https://mikeshake.me/ethical-dilemmas-in-artificial-intelligence/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://mikeshake.me/ethical-dilemmas-in-artificial-intelligence/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=https://mikeshake.me/ethical-dilemmas-in-artificial-intelligence/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>
</div><!-- /.social-share -->
        <p class="byline"><strong>Ethical Dilemmas in Artificial Intelligence</strong> was published on <time datetime="2016-02-22T00:00:00-05:00">February 22, 2016</time>.</p>
      </footer>
    </div><!-- /.article-wrap -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="https://mikeshake.me/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="https://mikeshake.me/experiment-design-and-analysis/" title="Experiment Design & Analysis">Experiment Design & Analysis</a></li>
    
      <li><a href="https://mikeshake.me/artificial-intelligence/" title="Artificial Intelligence">Artificial Intelligence</a></li>
    
      <li><a href="https://mikeshake.me/machine-learning/" title="Machine Learning">Machine Learning</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    
  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://mikeshake.me/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://mikeshake.me/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-41409977-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



<script>
$('.force-full-width-keep-aspect-ratio').each(function() {
  var iFrame = $(this);
  var originalWidth = $(this).width();
  var originalHeight = $(this).height();
  iFrame.css('width', '100%');
  $(window).resize(function() {
    iFrame.css('height', Math.ceil(iFrame.width() / originalWidth * originalHeight * 0.975) + 'px');
  });
});
$(window).resize();
</script>

</body>
</html>
